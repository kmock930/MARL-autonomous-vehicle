{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b019448",
   "metadata": {},
   "source": [
    "# Proof-of-concept: Further Communications Protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36092c",
   "metadata": {},
   "source": [
    "This notebook experiments further communication algorithms other than MAPPO (our baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa483b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "ROOT = os.path.join(os.path.dirname(os.curdir), '..')\n",
    "SIMPLEGRID_PATH = os.path.join(ROOT, 'gym-simplegrid', 'gym_simplegrid', 'envs')\n",
    "sys.path.append(ROOT)\n",
    "sys.path.append(SIMPLEGRID_PATH)\n",
    "from simple_grid import SimpleGridEnv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b667ce",
   "metadata": {},
   "source": [
    "## Recall Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d181687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell values\n",
    "FREE: int = 0\n",
    "OBSTACLE_SOFT: int = 1\n",
    "OBSTACLE_HARD: int = 2\n",
    "AGENT: int = 3\n",
    "TARGET: int = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aed721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Observability Definition\n",
    "observation_radius = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5572de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION_SPACE: [('UP', (-1, 0)), ('DOWN', (1, 0)), ('LEFT', (0, -1)), ('RIGHT', (0, 1)), ('UP_LEFT', (-1, -1)), ('UP_RIGHT', (-1, 1)), ('DOWN_LEFT', (1, -1)), ('DOWN_RIGHT', (1, 1)), ('STAY', (0, 0))]\n",
      "REWARDS: [('SOFT_OBSTACLE', -10), ('HARD_OBSTACLE', -50), ('TARGET', 50), ('STEP', -1), ('STAY', -3)]\n",
      "LEADER_MESSAGE_SIZE: 8\n"
     ]
    }
   ],
   "source": [
    "from constants import ACTION_SPACE, REWARDS, LEADER_MESSAGE_SIZE\n",
    "print(\"ACTION_SPACE:\", [(action.name, action.value )for action in ACTION_SPACE])\n",
    "print(\"REWARDS:\", [(reward.name, reward.value) for reward in REWARDS])\n",
    "print(\"LEADER_MESSAGE_SIZE:\", LEADER_MESSAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a825164",
   "metadata": {},
   "source": [
    "## DIAL (Differentiable Inter-Agent Learning) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963b3ea",
   "metadata": {},
   "source": [
    "### Design the Network's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afe6008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_logits       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ message (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m264\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m576\u001b[0m │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_logits       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │        \u001b[38;5;34m585\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ message (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,010</span> (7.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,010\u001b[0m (7.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,010</span> (7.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,010\u001b[0m (7.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_leader_model(observation_radius: int, leader_message_size: int):\n",
    "    '''\n",
    "        LEADER MODEL: Observe the state and Make its own decision + Send a message to the FOLLOWER\n",
    "\n",
    "        Args:\n",
    "            Input shape: LEADER Observable State\n",
    "\n",
    "        Returns:\n",
    "            Output shape: LEADER Action Probabilities + Leader's Message\n",
    "    '''\n",
    "    # Shared layers\n",
    "    inputs = tf.keras.layers.Input(shape=(1 + observation_radius * 2, 1 + observation_radius * 2))\n",
    "    x = tf.keras.layers.Reshape((-1, 1))(inputs) # Flatten spatial grid to sequence: (batch_size, time_steps = flattened size, features = 1)\n",
    "    x = tf.keras.layers.GRU(leader_message_size, activation='softmax', return_sequences=False)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='softmax')(x)\n",
    "\n",
    "    # Action head\n",
    "    action_logits = tf.keras.layers.Dense(len(ACTION_SPACE), activation='linear', name=\"action_logits\")(x)\n",
    "\n",
    "    # Message head\n",
    "    message = tf.keras.layers.Dense(leader_message_size, activation='sigmoid', name=\"message\")(x)\n",
    "\n",
    "    # Value Prediction\n",
    "    value = tf.keras.layers.Dense(1)(x)  # Value prediction\n",
    "\n",
    "    # Model\n",
    "    leader_model = tf.keras.Model(inputs=inputs, outputs=[action_logits, message, value])\n",
    "    leader_model.summary()\n",
    "    return leader_model\n",
    "leader_model = build_leader_model(observation_radius, LEADER_MESSAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a1820e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_logits       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m12,864\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_logits       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │        \u001b[38;5;34m585\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,609</span> (68.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,609\u001b[0m (68.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,609</span> (68.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,609\u001b[0m (68.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_follower_model(observation_radius: int, leader_message_size: int):\n",
    "    '''\n",
    "        FOLLOWER MODEL: Observe the state + Receive a message from the LEADER + Make its own decision\n",
    "\n",
    "        Args:\n",
    "            Input shape: FOLLOWER Observable State + Message from LEADER\n",
    "        \n",
    "        Returns:\n",
    "            Output shape: FOLLOWER Action Probabilities\n",
    "    '''\n",
    "    # Shared Input layers\n",
    "    state_input_layer = tf.keras.layers.Input(shape=(1 + observation_radius * 2, 1 + observation_radius * 2))\n",
    "    message_input_layer = tf.keras.layers.Input(shape=(leader_message_size,))\n",
    "\n",
    "    # Flatten spatial grid to sequence: (batch_size, time_steps = flattened size, features = 1)\n",
    "    state_reshaped = tf.keras.layers.Reshape((-1, 1))(state_input_layer)\n",
    "    message_reshaped = tf.keras.layers.Reshape((-1, 1))(message_input_layer)\n",
    "\n",
    "    # Combine state and message inputs (NO value_input_layer anymore)\n",
    "    combined_input = tf.keras.layers.Concatenate(axis=1)([state_reshaped, message_reshaped])\n",
    "\n",
    "    x = tf.keras.layers.GRU(64, activation='relu', return_sequences=False)(combined_input)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "    action_logits = tf.keras.layers.Dense(len(ACTION_SPACE), activation='linear', name=\"action_logits\")(x)\n",
    "\n",
    "    # Model\n",
    "    follower_model = tf.keras.Model(inputs=[state_input_layer, message_input_layer], outputs=[action_logits])\n",
    "    follower_model.summary()\n",
    "    return follower_model\n",
    "follower_model = build_follower_model(observation_radius, LEADER_MESSAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7dcb62",
   "metadata": {},
   "source": [
    "### Try to Run the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ea358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10x10 Grid Map:\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4 0]\n",
      " [0 2 0 0 0 1 3 1 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 1 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def generate_grid():\n",
    "    # Sample Grid Map\n",
    "    grid_map = np.zeros((10, 10), dtype=int)\n",
    "    \n",
    "    # Place 2 agents\n",
    "    agent_positions = []\n",
    "    while len(agent_positions) < 2:\n",
    "        x, y = np.random.randint(0, 10, size=2)\n",
    "        if grid_map[x, y] == FREE:\n",
    "            grid_map[x, y] = AGENT\n",
    "            agent_positions.append((x, y))\n",
    "    \n",
    "    # Place 1 target\n",
    "    while True:\n",
    "        x, y = np.random.randint(0, 10, size=2)\n",
    "        if grid_map[x, y] == FREE:\n",
    "            grid_map[x, y] = TARGET\n",
    "            break\n",
    "\n",
    "    # Place 5 soft obstacles\n",
    "    for _ in range(5):\n",
    "        while True:\n",
    "            x, y = np.random.randint(0, 10, size=2)\n",
    "            if grid_map[x, y] == FREE:\n",
    "                grid_map[x, y] = OBSTACLE_SOFT\n",
    "                break\n",
    "\n",
    "    # Place 5 hard obstacles\n",
    "    for _ in range(5):\n",
    "        while True:\n",
    "            x, y = np.random.randint(0, 10, size=2)\n",
    "            if grid_map[x, y] == FREE:\n",
    "                grid_map[x, y] = OBSTACLE_HARD\n",
    "                break\n",
    "\n",
    "    return grid_map\n",
    "\n",
    "print(\"10x10 Grid Map:\")\n",
    "grid_map = generate_grid()\n",
    "print(grid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186ec3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leader Agent Position: [1 8]\n",
      "Follower Agent Position: [7 6]\n"
     ]
    }
   ],
   "source": [
    "def get_agents_info(grid_map):\n",
    "    # Defining Leader vs Follower agents\n",
    "    # Randomly select positions for leader and follower agents from the grid map\n",
    "    agent_positions = np.argwhere(grid_map == AGENT)\n",
    "    if len(agent_positions) > 0:\n",
    "        leader_position = agent_positions[0]  # Assign the first agent position to the leader\n",
    "        follower_position = agent_positions[1] if len(agent_positions) > 1 else None  # Assign the second agent position to the follower if available\n",
    "    else:\n",
    "        leader_position = None\n",
    "        follower_position = None\n",
    "\n",
    "    leader_agent = {'position': leader_position, 'role': 'leader'}\n",
    "    follower_agent = {'position': follower_position, 'role': 'follower'}\n",
    "    return leader_agent, follower_agent\n",
    "\n",
    "leader_agent, follower_agent = get_agents_info(grid_map)\n",
    "\n",
    "print(\"Leader Agent Position:\", leader_agent['position'])\n",
    "print(\"Follower Agent Position:\", follower_agent['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23e98c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leader Partial Observability:\n",
      "[[0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]]\n",
      "Follower Partial Observability:\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 4]\n",
      " [0 1 3 1 2]\n",
      " [0 0 0 0 0]\n",
      " [1 2 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "state_leader = grid_map[leader_agent['position'][0], leader_agent['position'][1]]\n",
    "state_follower = grid_map[follower_agent['position'][0], follower_agent['position'][1]]\n",
    "# Extract partial observability for the leader\n",
    "x, y = leader_agent['position']\n",
    "leader_partial_observability = grid_map[\n",
    "    max(0, x - observation_radius):min(grid_map.shape[0], x + observation_radius + 1),\n",
    "    max(0, y - observation_radius):min(grid_map.shape[1], y + observation_radius + 1)\n",
    "]\n",
    "# Extract partial observability for the follower\n",
    "x, y = follower_agent['position']\n",
    "follower_partial_observability = grid_map[\n",
    "    max(0, x - observation_radius):min(grid_map.shape[0], x + observation_radius + 1),\n",
    "    max(0, y - observation_radius):min(grid_map.shape[1], y + observation_radius + 1)\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Leader Partial Observability:\")\n",
    "print(leader_partial_observability)\n",
    "print(\"Follower Partial Observability:\")\n",
    "print(follower_partial_observability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72525eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the observation in case some parts are out of the grid\n",
    "def pad_observation(obs, target_shape=(5, 5)):\n",
    "    h, w = obs.shape\n",
    "    target_h, target_w = target_shape\n",
    "\n",
    "    pad_height = max(target_h - h, 0)\n",
    "    pad_width = max(target_w - w, 0)\n",
    "\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "\n",
    "    padded_obs = np.pad(obs, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return padded_obs\n",
    "padded_leader_obs = pad_observation(leader_partial_observability, target_shape=(1 + observation_radius * 2, 1 + observation_radius * 2))\n",
    "padded_follower_obs = pad_observation(follower_partial_observability, target_shape=(1 + observation_radius * 2, 1 + observation_radius * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a23e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPPO:\n",
    "    def __init__(self, leader_model, follower_model, lr=0.001):\n",
    "        self.leader_model = leader_model\n",
    "        self.follower_model = follower_model\n",
    "        self.lr = lr\n",
    "\n",
    "    @staticmethod\n",
    "    def contrastive_loss(messages, positive_pairs, temperature=0.1):\n",
    "        \"\"\"\n",
    "        Compute the contrastive loss for communication alignment.\n",
    "\n",
    "        Parameters:\n",
    "        - messages: Tensor of shape (batch_size, embedding_dim), normalized embeddings.\n",
    "        - positive_pairs: List of indices representing positive pairs.\n",
    "        - temperature: Temperature parameter for scaling the similarity matrix.\n",
    "\n",
    "        Returns:\n",
    "        - loss: Contrastive loss value.\n",
    "        \"\"\"\n",
    "        # Normalize the embeddings\n",
    "        messages = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(messages)\n",
    "        # Compute the similarity matrix\n",
    "        sim_matrix = tf.matmul(messages, messages, transpose_b=True) / temperature\n",
    "        sim_matrix = tf.reshape(sim_matrix, (-1, 1))\n",
    "        # Create one-hot labels for positive pairs\n",
    "        labels = tf.one_hot(positive_pairs, depth=len(messages))\n",
    "        labels = tf.reshape(labels, (-1, 1))\n",
    "\n",
    "        # Compute the binary cross-entropy loss\n",
    "        print(\"labels\", labels)\n",
    "        print(\"sim_matrix\", sim_matrix)\n",
    "        loss = tf.keras.losses.binary_crossentropy(y_true=labels, y_pred=sim_matrix, from_logits=True)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    def compute_loss(self, leader_partial_observability, follower_partial_observability, leader_message, action_logits, actions, value, reward, hyperparams: dict = None):\n",
    "        '''\n",
    "            Compute the loss for the MAPPO algorithm.\n",
    "\n",
    "            Args:\n",
    "                leader_partial_observability: Observations from the leader agent.\n",
    "                follower_partial_observability: Observations from the follower agent.\n",
    "                leader_message: Message sent by the leader agent.\n",
    "                action_logits: Action logits from the model.\n",
    "                actions: True actions taken by the agents.\n",
    "                reward: Rewards received by the agents.\n",
    "                value: Predicted value from the model.\n",
    "                hyperparams: Hyperparameters for the loss function.\n",
    "                \n",
    "            Returns:\n",
    "                loss: Computed loss value.\n",
    "        '''\n",
    "        # Hyperparameters\n",
    "        contrastive_weight = 0.5  # Default value\n",
    "        reconstruction_loss_weight = 0.2  # Default value\n",
    "        entropy_bonus_weight = 0.01  # Default value\n",
    "        if hyperparams:\n",
    "            contrastive_weight = hyperparams.get('contrastive_weight', contrastive_weight)\n",
    "            reconstruction_loss_weight = hyperparams.get('reconstruction_loss_weight', reconstruction_loss_weight)\n",
    "            entropy_bonus_weight = hyperparams.get('entropy_bonus_weight', entropy_bonus_weight)\n",
    "        \n",
    "        leader_state = leader_partial_observability\n",
    "        follower_state = follower_partial_observability\n",
    "\n",
    "        # Compute Advantage (A = R + γV(s') - V(s))\n",
    "        value = reward - value  # Predicted value\n",
    "        advantage = reward - value  # TD error as Advantage Estimate\n",
    "        print(\"loss\", advantage)\n",
    "\n",
    "         # Policy Gradient Loss (A2C)\n",
    "        action_prob_leader = action_logits\n",
    "        safe_action_prob_leader = tf.clip_by_value(action_prob_leader, 1e-8, 1.0)\n",
    "        policy_loss = -tf.reduce_mean(advantage * tf.math.log(safe_action_prob_leader))\n",
    "        print('Policy Gradient Loss', policy_loss)\n",
    "\n",
    "        follower_state_reshaped = tf.expand_dims(tf.convert_to_tensor(follower_partial_observability, dtype=tf.float32), axis=0)\n",
    "        follower_state_reshaped = tf.reshape(follower_state_reshaped, (1, 1 + observation_radius * 2, 1 + observation_radius * 2))\n",
    "        action_prob_follower = self.follower_model([follower_state_reshaped, leader_message], training=True)\n",
    "\n",
    "        # Contrastive Loss (CACL) for Communication Alignment\n",
    "        contrastive_loss_value = tf.clip_by_value(\n",
    "            self.contrastive_loss(tf.convert_to_tensor([action_prob_follower]), positive_pairs=[0]),\n",
    "            clip_value_min=0.0,\n",
    "            clip_value_max=10.0\n",
    "        )\n",
    "        print('Contrastive Loss', contrastive_loss_value)\n",
    "\n",
    "        # Message Reconstruction Loss (L_recon)\n",
    "        print(f'leader_message={action_prob_leader}')\n",
    "        print(f'decoded_message= {action_prob_follower}')\n",
    "\n",
    "        # Align shapes of leader_message and decoded_message\n",
    "        min_dim = min(action_prob_leader.shape[-1], action_prob_follower.shape[-1])\n",
    "        leader_message_aligned = action_prob_leader[..., :min_dim]\n",
    "        decoded_message_aligned = action_prob_follower[..., :min_dim]\n",
    "\n",
    "        # CCompute reconstruction loss\n",
    "        reconstruction_loss = tf.clip_by_value(\n",
    "            tf.reduce_mean(tf.keras.losses.MSE(leader_message_aligned, decoded_message_aligned)),\n",
    "            clip_value_min=0.0,\n",
    "            clip_value_max=10.0\n",
    "        )\n",
    "        print('Reconstruction Loss', reconstruction_loss)\n",
    "\n",
    "        # Entropy Bonus for Exploration\n",
    "        # Clip the entropy bonus to avoid extreme values\n",
    "        entropy_bonus = tf.clip_by_value(\n",
    "            -tf.reduce_mean(action_prob_leader * tf.math.log(action_prob_leader + 1e-8)),\n",
    "            clip_value_min=0.0,\n",
    "            clip_value_max=10.0\n",
    "        )\n",
    "        print('Entropy Bonus', entropy_bonus)\n",
    "\n",
    "        # Final loss function\n",
    "        total_loss = policy_loss + entropy_bonus_weight * entropy_bonus + contrastive_weight * contrastive_loss_value + reconstruction_loss_weight * reconstruction_loss\n",
    "        print('Total Loss', total_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def apply_gradients(self, state_leader, decoded_msg, action_leader, action_follower, reward, leader_message, encoded_message, decoded_message):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.compute_loss(\n",
    "                state_leader=state_leader,\n",
    "                decoded_msg=decoded_msg,\n",
    "                action_leader=action_leader,\n",
    "                action_follower=action_follower,\n",
    "                reward=reward,\n",
    "                leader_message=leader_message,\n",
    "                encoded_message=encoded_message,\n",
    "                decoded_message=decoded_message\n",
    "            )\n",
    "        grads = tape.gradient(loss, self.leader_model.trainable_variables + self.follower_model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.leader_model.trainable_variables + self.follower_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc6d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Episode 1/1\n",
      "leader_obs_input (1, 5, 5)\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "leader_obs_input (1, 5, 5)\n",
      "Leader move out of bounds. Staying in place.\n",
      "follower_obs_input (1, 5, 5)\n",
      "Follower move out of bounds. Staying in place.\n",
      "loss tf.Tensor([[-0.0352338]], shape=(1, 1), dtype=float32)\n",
      "Policy Gradient Loss tf.Tensor(-0.53983694, shape=(), dtype=float32)\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[89.99999]], shape=(1, 1), dtype=float32)\n",
      "Contrastive Loss tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "leader_message=[[-0.02156862 -0.00935218 -0.00076089 -0.0368416  -0.01761251  0.01170359\n",
      "  -0.0483242   0.0110927  -0.01374189]]\n",
      "decoded_message= [[ 0.00261947  0.05250008  0.04822424 -0.0317661   0.02526565  0.02426799\n",
      "  -0.02327193 -0.03178857  0.01627291]]\n",
      "Reconstruction Loss tf.Tensor(0.0013555309, shape=(), dtype=float32)\n",
      "Entropy Bonus tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Total Loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "labels tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "sim_matrix tf.Tensor([[90.]], shape=(1, 1), dtype=float32)\n",
      "Episode 1: Total Reward = -100\n",
      "Training logs exported to 'evaluation_metrics.csv'\n",
      "✅Training completed.\n"
     ]
    }
   ],
   "source": [
    "def train_MAPPO(episodes, leader_model, follower_model, env, hyperparams: dict = None, algorithm=\"MAPPO\"):\n",
    "    leader_model.compile()\n",
    "    follower_model.compile()\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Logging\n",
    "    episode_logs = []\n",
    "\n",
    "    # Hyperparameters\n",
    "    lr = hyperparams.get('lr', 0.001) if hyperparams else 0.001\n",
    "    max_step_per_episode = hyperparams.get('max_steps', 100) if hyperparams else 100\n",
    "    max_episodes = hyperparams.get('max_episodes', 100) if hyperparams else 100\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # Initialize MAPPO model\n",
    "    mappo_model = MAPPO(\n",
    "        leader_model=leader_model,\n",
    "        follower_model=follower_model,\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    episodes = episodes or max_episodes\n",
    "    for episode in range(episodes):\n",
    "        print(f\"\\nEpisode {episode + 1}/{episodes}\")\n",
    "\n",
    "        # Reset environment\n",
    "        grid_map = generate_grid()\n",
    "        leader_pos = get_agents_info(grid_map)[0]['position']\n",
    "        follower_pos = get_agents_info(grid_map)[1]['position']\n",
    "        target_pos = np.argwhere(grid_map == TARGET)[0]\n",
    "\n",
    "        total_reward = 0\n",
    "        tether_violated, collisions = 0, 0\n",
    "        distances = []\n",
    "\n",
    "        episode_log = {\"episode\": episode + 1} # human readable episode number\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for step in range(max_step_per_episode):\n",
    "                # === Leader ===\n",
    "                x, y = leader_pos\n",
    "\n",
    "                leader_obs_input = tf.expand_dims(\n",
    "                    tf.reshape(tf.convert_to_tensor(padded_leader_obs.astype(np.float32)),\n",
    "                            (padded_leader_obs.shape[0], padded_leader_obs.shape[1])),\n",
    "                    axis=0\n",
    "                )\n",
    "                print(\"leader_obs_input\", leader_obs_input.shape)\n",
    "\n",
    "                action_logits_leader, message, value_prediction = leader_model(leader_obs_input, training=True)\n",
    "                action_prob_leader = tf.nn.softmax(action_logits_leader)\n",
    "                leader_action_idx = tf.argmax(action_prob_leader[0]).numpy()\n",
    "                leader_action = list(ACTION_SPACE)[leader_action_idx]\n",
    "\n",
    "                # Update leader position\n",
    "                new_leader_pos = [leader_pos[0] + leader_action.value[0], leader_pos[1] + leader_action.value[1]]\n",
    "                if 0 <= new_leader_pos[0] < grid_map.shape[0] and 0 <= new_leader_pos[1] < grid_map.shape[1]:\n",
    "                    grid_map[leader_pos[0], leader_pos[1]] = FREE\n",
    "                    leader_pos = new_leader_pos\n",
    "                    grid_map[leader_pos[0], leader_pos[1]] = AGENT\n",
    "                else:\n",
    "                    print(\"Leader move out of bounds. Staying in place.\")\n",
    "\n",
    "                # === Follower ===\n",
    "                follower_obs_input = tf.expand_dims(\n",
    "                    tf.reshape(tf.convert_to_tensor(padded_follower_obs.astype(np.float32)),\n",
    "                            (padded_follower_obs.shape[0], padded_follower_obs.shape[1])),\n",
    "                    axis=0\n",
    "                )\n",
    "                print(\"follower_obs_input\", follower_obs_input.shape)\n",
    "\n",
    "                follower_action_logits = follower_model([follower_obs_input, message], training=True)\n",
    "                action_prob_follower = tf.nn.softmax(follower_action_logits)\n",
    "                follower_action_idx = tf.argmax(action_prob_follower[0]).numpy()\n",
    "                follower_action = list(ACTION_SPACE)[follower_action_idx]\n",
    "\n",
    "                # Update follower position\n",
    "                new_follower_pos = [follower_pos[0] + follower_action.value[0], follower_pos[1] + follower_action.value[1]]\n",
    "                if 0 <= new_follower_pos[0] < grid_map.shape[0] and 0 <= new_follower_pos[1] < grid_map.shape[1]:\n",
    "                    grid_map[follower_pos[0], follower_pos[1]] = FREE\n",
    "                    follower_pos = new_follower_pos\n",
    "                    grid_map[follower_pos[0], follower_pos[1]] = AGENT\n",
    "                else:\n",
    "                    print(\"Follower move out of bounds. Staying in place.\")\n",
    "\n",
    "                # === Compute reward ===\n",
    "                distance = np.linalg.norm(np.array(leader_pos) - np.array(follower_pos))\n",
    "                distances.append(distance)\n",
    "\n",
    "                step_reward = -1  # step penalty\n",
    "                if distance > 2 or distance < 1:\n",
    "                    tether_violated += 1\n",
    "                if np.array_equal(leader_pos, target_pos) or np.array_equal(follower_pos, target_pos):\n",
    "                    step_reward += REWARDS.TARGET.value\n",
    "                if (grid_map[leader_pos[0], leader_pos[1]] == OBSTACLE_HARD or\n",
    "                        grid_map[follower_pos[0], follower_pos[1]] == OBSTACLE_HARD):\n",
    "                    step_reward += REWARDS.CRASH.value\n",
    "                    collisions += 1\n",
    "\n",
    "                total_reward += step_reward\n",
    "\n",
    "                # === Compute loss ===\n",
    "                loss = mappo_model.compute_loss(\n",
    "                    leader_partial_observability=tf.reshape(leader_obs_input, (1, -1)),\n",
    "                    follower_partial_observability=tf.reshape(follower_obs_input, (1, -1)),\n",
    "                    leader_message=message,\n",
    "                    action_logits=action_logits_leader,\n",
    "                    actions=[leader_action_idx, follower_action_idx],\n",
    "                    value=value_prediction,\n",
    "                    reward=tf.convert_to_tensor([step_reward], dtype=tf.float32),\n",
    "                    hyperparams=None\n",
    "                )\n",
    "\n",
    "            # === After episode: Backpropagate ===\n",
    "            grads = tape.gradient(loss, leader_model.trainable_variables + follower_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, leader_model.trainable_variables + follower_model.trainable_variables))\n",
    "\n",
    "        # === Logging ===\n",
    "        avg_distance = np.mean(distances) if distances else 0\n",
    "        entropy_bonus = -tf.reduce_mean(action_prob_leader * tf.math.log(action_prob_leader + 1e-8))\n",
    "        contrastive_loss = float(mappo_model.contrastive_loss(messages=tf.convert_to_tensor([action_prob_follower]), positive_pairs=[0]))\n",
    "\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "        episode_log.update({\n",
    "            \"reward\": total_reward,\n",
    "            \"avg_distance\": avg_distance,\n",
    "            \"policy_loss\": float(loss),\n",
    "            \"contrastive_loss\": contrastive_loss,\n",
    "            \"entropy\": float(entropy_bonus),\n",
    "            \"tether_violations\": tether_violated,\n",
    "            \"collisions\": collisions,\n",
    "            \"hyperparams\": hyperparams,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"num_episodes\": episodes\n",
    "        })\n",
    "\n",
    "        episode_logs.append(episode_log)\n",
    "\n",
    "    # === Export logs ===\n",
    "    logs_df = pd.DataFrame(episode_logs)\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    logs_df.to_csv(\"logs/evaluation_metrics.csv\", index=False)\n",
    "    print(f\"Training logs exported to 'evaluation_metrics.csv'\")\n",
    "    print(\"✅Training completed.\")\n",
    "\n",
    "# Call the function\n",
    "train_MAPPO(\n",
    "    episodes=1,\n",
    "    leader_model=leader_model,\n",
    "    follower_model=follower_model,\n",
    "    env=None,  # Placeholder for the environment\n",
    "    hyperparams={\n",
    "        'lr': 0.001,\n",
    "        'max_steps': 100,\n",
    "        'max_episodes': 1\n",
    "    },\n",
    "    algorithm=\"MAPPO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44dc0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "leader_model.save('leader_model.h5')\n",
    "follower_model.save('follower_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ae1b7",
   "metadata": {},
   "source": [
    "## Make Prediction on an Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481a78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_leader_action(leader_model, leader_obs_input):\n",
    "    leader_obs_input = tf.convert_to_tensor(leader_obs_input, dtype=tf.float32)\n",
    "    leader_obs_input = tf.expand_dims(tf.reshape(leader_obs_input, (leader_obs_input.shape[0], leader_obs_input.shape[1])), axis=0)\n",
    "\n",
    "    action_logits_leader, message, value_prediction = leader_model(leader_obs_input, training=False)\n",
    "    action_prob_leader = tf.nn.softmax(action_logits_leader)\n",
    "    action_idx = tf.argmax(action_prob_leader, axis=-1).numpy()[0]\n",
    "    action = list(ACTION_SPACE)[action_idx]\n",
    "    return action, message, value_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a58517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_follower_action(follower_model, follower_obs_input, leader_message):\n",
    "    # Ensure input shapes\n",
    "    follower_obs_input = tf.convert_to_tensor(follower_obs_input, dtype=tf.float32)\n",
    "    follower_obs_input = tf.expand_dims(tf.reshape(follower_obs_input, (follower_obs_input.shape[0], follower_obs_input.shape[1])), axis=0)\n",
    "\n",
    "    leader_message = tf.convert_to_tensor(leader_message, dtype=tf.float32)\n",
    "    leader_message = tf.expand_dims(leader_message, axis=0) if len(leader_message.shape) == 1 else leader_message\n",
    "\n",
    "    action_logits_follower = follower_model([follower_obs_input, leader_message], training=False)\n",
    "    action_prob_follower = tf.nn.softmax(action_logits_follower)\n",
    "    action_idx = tf.argmax(action_prob_follower, axis=-1).numpy()[0]\n",
    "    action = list(ACTION_SPACE)[action_idx]\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ab6fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leader Action: UP (-1, 0)\n",
      "Follower Action: UP (-1, 0)\n"
     ]
    }
   ],
   "source": [
    "# Leader step\n",
    "leader_action, leader_message, leader_value = predict_leader_action(leader_model, padded_leader_obs)\n",
    "\n",
    "# Follower step\n",
    "follower_action = predict_follower_action(follower_model, padded_follower_obs, leader_message)\n",
    "\n",
    "print(\"Leader Action:\", leader_action.name, leader_action.value)\n",
    "print(\"Follower Action:\", follower_action.name, follower_action.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc43fb",
   "metadata": {},
   "source": [
    "## Put the Agents into Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a56ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_move(position, grid_map, leader_pos, follower_pos, tether_limit=2):\n",
    "    x, y = position\n",
    "    # Check bounds and hard obstacles\n",
    "    if not (0 <= x < grid_map.shape[0] and 0 <= y < grid_map.shape[1]) or grid_map[x, y] == OBSTACLE_HARD:\n",
    "        return False\n",
    "    # Check if position hits another agent\n",
    "    if np.array_equal(position, leader_pos) or np.array_equal(position, follower_pos):\n",
    "        return False\n",
    "    # Check tether limit\n",
    "    if np.floor(np.sqrt((position[0] - leader_pos[0])**2 + (position[1] - leader_pos[1])**2)) > tether_limit:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bcf9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(leader_model, follower_model, max_steps=100):\n",
    "    print(\"\\n Starting Play Mode Episode\")\n",
    "    \n",
    "    # Reset environment\n",
    "    grid_map = generate_grid()\n",
    "    leader_pos = np.array(get_agents_info(grid_map)[0]['position'])\n",
    "    follower_pos = np.array(get_agents_info(grid_map)[1]['position'])\n",
    "    target_pos = np.argwhere(grid_map == TARGET)[0]\n",
    "\n",
    "    leader_path = [leader_pos.copy()]\n",
    "    follower_path = [follower_pos.copy()]\n",
    "    total_reward = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        print(f\"\\nStep {step + 1}/{max_steps}\")\n",
    "\n",
    "        # === Leader Prediction ===\n",
    "        leader_obs = grid_map[\n",
    "            max(0, leader_pos[0] - observation_radius):min(grid_map.shape[0], leader_pos[0] + observation_radius + 1),\n",
    "            max(0, leader_pos[1] - observation_radius):min(grid_map.shape[1], leader_pos[1] + observation_radius + 1)\n",
    "        ]\n",
    "        padded_leader_obs = pad_observation(leader_obs, (1 + observation_radius * 2, 1 + observation_radius * 2))\n",
    "        leader_action, leader_message, _ = predict_leader_action(leader_model, padded_leader_obs)\n",
    "\n",
    "        print(f\"Leader Action: {leader_action}, Leader Pos: {leader_pos}\")\n",
    "\n",
    "        # Update leader position\n",
    "        new_leader_pos = [leader_pos[0] + leader_action.value[0], leader_pos[1] + leader_action.value[1]]\n",
    "        if is_valid_move(new_leader_pos, grid_map, leader_pos, follower_pos):\n",
    "            grid_map[leader_pos[0], leader_pos[1]] = FREE\n",
    "            leader_pos = new_leader_pos\n",
    "            grid_map[leader_pos[0], leader_pos[1]] = AGENT\n",
    "        else:\n",
    "            print(\"Invalid move for leader. Resetting game.\")\n",
    "            return play_episode(leader_model, follower_model, max_steps)\n",
    "        leader_path.append(leader_pos.copy())\n",
    "\n",
    "        # === Follower Prediction ===\n",
    "        follower_obs = grid_map[\n",
    "            max(0, follower_pos[0] - observation_radius):min(grid_map.shape[0], follower_pos[0] + observation_radius + 1),\n",
    "            max(0, follower_pos[1] - observation_radius):min(grid_map.shape[1], follower_pos[1] + observation_radius + 1)\n",
    "        ]\n",
    "        padded_follower_obs = pad_observation(follower_obs, (1 + observation_radius * 2, 1 + observation_radius * 2))\n",
    "        follower_action = predict_follower_action(follower_model, padded_follower_obs, leader_message)\n",
    "\n",
    "        print(f\"Follower Action: {follower_action}, Follower Pos: {follower_pos}\")\n",
    "\n",
    "        # Update follower position\n",
    "        new_follower_pos = [follower_pos[0] + follower_action.value[0], follower_pos[1] + follower_action.value[1]]\n",
    "        if is_valid_move(new_follower_pos, grid_map, leader_pos, follower_pos):\n",
    "            grid_map[follower_pos[0], follower_pos[1]] = FREE\n",
    "            follower_pos = new_follower_pos\n",
    "            grid_map[follower_pos[0], follower_pos[1]] = AGENT\n",
    "        else:\n",
    "            print(\"Invalid move for follower. Resetting game.\")\n",
    "            return play_episode(leader_model, follower_model, max_steps)\n",
    "        follower_path.append(follower_pos.copy())\n",
    "\n",
    "        # Check termination\n",
    "        if np.array_equal(leader_pos, target_pos) or np.array_equal(follower_pos, target_pos):\n",
    "            print(\"Target reached!\")\n",
    "            break\n",
    "\n",
    "        total_reward -= 1  # Step penalty\n",
    "\n",
    "    print(f\"\\n✅ Episode finished. Total Reward: {total_reward}\")\n",
    "    print(f\"Leader Path: {leader_path}\")\n",
    "    print(f\"Follower Path: {follower_path}\")\n",
    "\n",
    "    return leader_path, follower_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67f5a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 4]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 2]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 3]\n",
      "\n",
      "Step 2/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(6), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(8), np.int64(3)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(1)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(6), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(8), np.int64(3)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(3)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(3)]\n",
      "\n",
      "Step 5/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(3)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(3)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(3)]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 0]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(1)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(3)]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 7]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 7]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(0)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(0)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(0)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(0)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 2]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 2]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(3)]\n",
      "\n",
      "Step 3/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(3)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(3)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(3)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 2]\n",
      "\n",
      "Step 2/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(4)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(2)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(2)]\n",
      "\n",
      "Step 5/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(2)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(2)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(4)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(4)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 5]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 5]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(5)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(7)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(5)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(7)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 1]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 7]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 7]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 1]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [9 4]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [9 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 5]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(8), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(8), np.int64(5)]\n",
      "\n",
      "Step 3/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 5]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(8), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(8), np.int64(5)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(7), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(5)]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(7), np.int64(4)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(5)]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 4]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(2)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 4]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(4)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(4)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 5]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(2)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(2)]\n",
      "\n",
      "Step 4/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(2)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(2)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(2)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(2)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(2)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 4]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(6)]\n",
      "\n",
      "Step 3/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(6)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(6)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(8)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(6)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(6)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(8)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(6)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(8)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 3]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 3]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(7), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(8), np.int64(3)]\n",
      "\n",
      "Step 3/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(7), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(8), np.int64(3)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(6), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(3)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(3)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(6), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(7), np.int64(3)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(5), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(3)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(3)]\n",
      "\n",
      "Step 6/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(3)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(3)]\n",
      "\n",
      "Step 6/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(3)]\n",
      "\n",
      "Step 7/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(3)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(3)]\n",
      "\n",
      "Step 7/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(3)]\n",
      "\n",
      "Step 8/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(3)]\n",
      "\n",
      "Step 9/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(3)]\n",
      "\n",
      "Step 8/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(3)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(3)]\n",
      "\n",
      "Step 9/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(3)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(3)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [9 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 9]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [9 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [1 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [1 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 9]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 8]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(9)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(8)]\n",
      "\n",
      "Step 3/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 8]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(9)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(8)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(9)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(8)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(9)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(9)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(8)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(9)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 4]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 1]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(1)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(1)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 8]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 8]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 4]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 3]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 7]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 3]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 7]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 7]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(8)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 7]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(7)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(7)]\n",
      "\n",
      "Step 4/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(7)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(7)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(7)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(8)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(7)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(7)]\n",
      "\n",
      "Step 6/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(8)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(7)]\n",
      "\n",
      "Step 6/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(8)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [7 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 8]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 8]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 2]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 8]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(6)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 8]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(6)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 4]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 3]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(2)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(7)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 6]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(6)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(6)]\n",
      "\n",
      "Step 4/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(5), np.int64(6)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(4), np.int64(6)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(6)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(7)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(7)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(6)]\n",
      "\n",
      "Step 5/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(7)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 5]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 3]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 3]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 7]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 8]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 1]\n",
      "\n",
      "Step 2/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 1]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(0)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 5]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [3 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 0]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 2]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 3]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 3]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(7)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(8)]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(2), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(3), np.int64(7)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(1), np.int64(8)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(7)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(8)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(2), np.int64(7)]\n",
      "\n",
      "Step 4/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(8)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [1 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [1 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 8]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 0]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 4]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 9]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 1]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 1]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 7]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(6)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(7)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(6)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(4), np.int64(6)]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [np.int64(6), np.int64(7)]\n",
      "\n",
      "Step 3/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(3), np.int64(6)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 6]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 1]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 9]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 6]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 6]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [5 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 0]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [7 2]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [8 0]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 6]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [0 9]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [1 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 5]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(5)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [2 5]\n",
      "\n",
      "Step 2/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [np.int64(0), np.int64(5)]\n",
      "Invalid move for leader. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [2 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [9 3]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [5 7]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 3]\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [4 5]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [6 8]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [3 3]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Target reached!\n",
      "\n",
      "✅ Episode finished. Total Reward: 0\n",
      "Leader Path: [array([6, 2]), [np.int64(5), np.int64(2)]]\n",
      "Follower Path: [array([8, 4]), [np.int64(7), np.int64(4)]]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [4 7]\n",
      "Invalid move for follower. Resetting game.\n",
      "\n",
      " Starting Play Mode Episode\n",
      "\n",
      "Step 1/100\n",
      "Leader Action: ACTION_SPACE.UP, Leader Pos: [6 2]\n",
      "Follower Action: ACTION_SPACE.UP, Follower Pos: [8 4]\n",
      "Target reached!\n",
      "\n",
      "✅ Episode finished. Total Reward: 0\n",
      "Leader Path: [array([6, 2]), [np.int64(5), np.int64(2)]]\n",
      "Follower Path: [array([8, 4]), [np.int64(7), np.int64(4)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([6, 2]), [np.int64(5), np.int64(2)]],\n",
       " [array([8, 4]), [np.int64(7), np.int64(4)]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_episode(leader_model, follower_model, max_steps=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
